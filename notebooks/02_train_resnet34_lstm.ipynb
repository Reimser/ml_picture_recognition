{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2cec319c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aktuelles Arbeitsverzeichnis: c:\\Users\\hp\\OneDrive\\Desktop\\DBU\\wai81-ai-theory\\ml_picture_recognition\n"
     ]
    }
   ],
   "source": [
    "# --- Erste Zelle ---\n",
    "import os\n",
    "import sys\n",
    "if os.getcwd().endswith('notebooks'):\n",
    "    os.chdir('..')\n",
    "sys.path.insert(0, os.getcwd())\n",
    "print(f\"Aktuelles Arbeitsverzeichnis: {os.getcwd()}\")\n",
    "\n",
    "# --- Danach alle Imports ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.dataloader import HockeyDataset\n",
    "from utils.transforms import train_transform, val_transform\n",
    "from utils.resnet34_lstm import ResNet34_LSTM\n",
    "\n",
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fcfa2b",
   "metadata": {},
   "source": [
    "Arbeitverzeichnis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75af90b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aktuelles Arbeitsverzeichnis: c:\\Users\\hp\\OneDrive\\Desktop\\DBU\\wai81-ai-theory\\ml_picture_recognition\n"
     ]
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "if current_dir.endswith('notebooks'):\n",
    "    os.chdir('..')\n",
    "sys.path.insert(0, os.getcwd())\n",
    "print(f\"Aktuelles Arbeitsverzeichnis: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0cf9b3",
   "metadata": {},
   "source": [
    "Parameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "135b7aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Pfade und Parameter ---\n",
    "TRAIN_CSV = 'data/labels_train.csv'\n",
    "VAL_CSV = 'data/labels_val.csv'\n",
    "FRAMES_ROOT = 'data/train_frames'  # Hier liegen deine Frames!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f68f9bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "NUM_WORKERS = 4\n",
    "NUM_CLASSES = 4              # 4 Labels: Check, Neutral, Schuss, Tor\n",
    "HIDDEN_DIM = 256\n",
    "LEARNING_RATE = 1e-4\n",
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "862a5588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Dataset & DataLoader ---\n",
    "train_dataset = HockeyDataset(csv_file=TRAIN_CSV, frames_root=FRAMES_ROOT, transform=train_transform)\n",
    "val_dataset = HockeyDataset(csv_file=VAL_CSV, frames_root=FRAMES_ROOT, transform=val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "452787ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Modell ---\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ResNet34_LSTM(hidden_dim=HIDDEN_DIM, num_classes=NUM_CLASSES).to(device)\n",
    "\n",
    "# --- Loss & Optimizer ---\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3fc52f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss 1.6232, F1 0.51 | Val Loss 1.4103, F1 0.60\n",
      "Epoch 2: Train Loss 1.2128, F1 0.74 | Val Loss 1.3292, F1 0.67\n",
      "Epoch 3: Train Loss 1.0216, F1 0.79 | Val Loss 1.2543, F1 0.73\n",
      "Epoch 4: Train Loss 0.8104, F1 0.85 | Val Loss 1.5766, F1 0.62\n",
      "Early Stopping Counter: 1/5\n",
      "Epoch 5: Train Loss 0.7670, F1 0.86 | Val Loss 1.2374, F1 0.68\n",
      "Early Stopping Counter: 2/5\n",
      "Epoch 6: Train Loss 0.7757, F1 0.86 | Val Loss 1.4990, F1 0.75\n",
      "Epoch 7: Train Loss 0.8465, F1 0.84 | Val Loss 1.2271, F1 0.70\n",
      "Early Stopping Counter: 1/5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     24\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 25\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     28\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\hp\\anaconda3\\envs\\picture\\lib\\site-packages\\torch\\_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    580\u001b[0m     )\n\u001b[1;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hp\\anaconda3\\envs\\picture\\lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hp\\anaconda3\\envs\\picture\\lib\\site-packages\\torch\\autograd\\graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    826\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    827\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# --- Vorbereitungen ---\n",
    "best_val_f1 = 0\n",
    "early_stopping_counter = 0\n",
    "patience = 5\n",
    "\n",
    "train_losses = []\n",
    "train_f1_scores = []\n",
    "val_losses = []\n",
    "val_f1_scores = []\n",
    "\n",
    "# --- Training Loop ---\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    all_preds, all_targets = [], []\n",
    "\n",
    "    for frames, labels in train_loader:\n",
    "        frames = frames.to(device)                     # (B, T, 3, 224, 224)\n",
    "        labels = labels.float().to(device)              # (B, 4)\n",
    "\n",
    "        outputs = model(frames)                         # (B, 4)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        all_preds.append((torch.sigmoid(outputs) > 0.5).cpu())\n",
    "        all_targets.append(labels.cpu())\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_f1 = f1_score(torch.cat(all_targets), torch.cat(all_preds), average=\"macro\", zero_division=0)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    train_f1_scores.append(train_f1)\n",
    "\n",
    "    # --- Validation ---\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_preds, val_targets = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for frames, labels in val_loader:\n",
    "            frames = frames.to(device)\n",
    "            labels = labels.float().to(device)\n",
    "\n",
    "            outputs = model(frames)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            val_preds.append((torch.sigmoid(outputs) > 0.5).cpu())\n",
    "            val_targets.append(labels.cpu())\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_f1 = f1_score(torch.cat(val_targets), torch.cat(val_preds), average=\"macro\", zero_division=0)\n",
    "\n",
    "    val_losses.append(val_loss)\n",
    "    val_f1_scores.append(val_f1)\n",
    "\n",
    "    # --- Fortschritt ausgeben ---\n",
    "    print(f\"Epoch {epoch+1}: Train Loss {train_loss:.4f}, F1 {train_f1:.2f} | Val Loss {val_loss:.4f}, F1 {val_f1:.2f}\")\n",
    "\n",
    "    # --- Early Stopping ---\n",
    "    if val_f1 > best_val_f1:\n",
    "        best_val_f1 = val_f1\n",
    "        early_stopping_counter = 0\n",
    "        torch.save(model.state_dict(), 'models/best_resnet34_lstm.pth')  # Bester Checkpoint\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "        print(f\"Early Stopping Counter: {early_stopping_counter}/{patience}\")\n",
    "        if early_stopping_counter >= patience:\n",
    "            print(\"⏹️ Early stopping triggered.\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18436fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- Save Model ---\n",
    "# torch.save(model.state_dict(), 'models/resnet34_lstm.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "picture",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
